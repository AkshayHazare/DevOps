<!DOCTYPE html>
<html>
    <head>
<!--include subhead.txt -->
        <title>
            The Art of Monitoring
        </title>
        <!--include googleAnalyticsScript.txt -->
    </head>

    <body>
        <div class="wrapper">
<!--include navbar.txt -->
    <div id = "content">
        <h1>
            The Art of Monitoring
        </h1>

        <p class="author">
            James Turnbull
        </p>
        <p>
            Reviewers: Jatri Dave , Tanya Jha
        </p>
    <details>
        <summary class="sum2">
         Chapter 1: An Introduction to Monitoring
        </summary>
      <p>
        <b>What is monitoring?</b><br>
        From a technological perspective, monitoring is the tools and
        processes by which you measure and manage your IT systems.
        Monitoring is something that provides the translation between business
        value and the metrics generated by your systems and applications.
        These metrics can be translated into measurable user experience, which
        in turn provides feedback to the business to help ensure the delivery
        of customers requirements. It also gives feedback on insufficient or
        nonworking services. <br>
        Monitoring system has two customers :
        (1) The business (2) Information Technology <br>
        The stages of a three-level maturity model reflecting
        monitoring evolution are :<br>
        <b>(i) Manual : </b> In this stage , monitoring is largely manual, user initiated,
        or not done at all.<br>
        <b>(ii) Reactive : </b> This type of monitoring is mostly automatic
        with some remnants of manual or unmonitored components.<br>
        <b>(iii) Proactive : </b>Here, monitoring is automatic and generated
        by configuration management. Example of different monitoring tools
        are Nagios, Sensu, and Graphite.<br/>
      </p>
  </details>
  <details>
      <summary class= "sum2">
        Chapter 2: A Monitoring, Metrics and Measurement
      </summary>
      <p>
      This chapter proposes an architecture for a monitoring framework.
      It also discusses the faults of traditional monitoring frameworks
      and compared the new architecture with it.
      The new architecture is based on "whitebox" or push based monitoring
      rather than a "blackbox" or pull based monitoring. In a white box or
      push based monitoring the components being monitored are queried. But
      in a "blackbox" or pull based monitoring the components being monitored
      send their data to a central collector. This kind of architecture
      is centered around collecting events,log and metrics. Metrics are
      properties of hardware and software. They are usually collected
      with as a value that occurred at a time stamp. These metrics can be
      transformed mathematically using sum, count, average, percentiles etc.
      If we have multiple sources, we may want to show aggregated result of
      the metrics across all the sources.
      A good visualization of data provides powerful analytics. It should
      clearly show the data without distorting it.
      </p>

  </details>
  <details>
      <summary class= "sum2">
        Chapter 3: Managing Events and metrics with Riemann
      </summary>
        Key design features for routing engine are as follows :
        <ul>
          <li> Receive events and metrics including scaling with growing
            environment. </li>
          <li>Maintain sufficient state to do event matching and provide
            context for notifications.</li>
          <li>Munge events including extracting metrics from events.</li>
          <li>Categorize and route data to be stored, graphed, alerted on,
            or sent to any other potential destinations.</li>
        </ul>
        <br>
        <p>
        <b>"If only I had the theorems! Then I should  nd the proofs
          easily enough."</b> -Bernard Riemann <br>
          Riemann is a monitoring tool that aggregates events from hosts
          and applications and can feed them into a stream processing
          language to be manipulated, summarized, or actioned. It can also
          track the state of incoming event and provides notifications.<br>
          A brief explanation on installing Riemann on three different hosts
          is given. Moreover, Configuring Riemann, Connecting Riemann servers,
          Alerting on the upstream Riemann servers, Testing, Validating,
          Performance, scaling, and making Riemann highly available
          is also explained in detail.
      </p>

  </details>
  <details>
      <summary class= "sum2">
        Chapter 4: Storing and graphing metrics, including Graphite and Grafana
      </summary>
      <p>The last chapter dealt with Reimann that provides a central
        destination and routing engine for the events and metrics. This
        chapter deals with the storage of the time series metrics. "Grpahite
        is an engine that stores time-series data and then can render
        graphs from that data using an API. Grafana is an
        open-source metrics dashboard that supports Graphite,
        InfluxDB, and OpenTSDB." Graphite is made up for 3 components -
        carbon, whisper and Graphite Web. Carbon is a collection of
        daemons that are event driven and listen on network ports. THey
        listen receive and write time series data. Whisper is a flat-file
        database used for storing time-series data. Graphite web is a
        Django-based web UI that can be used to compose graphs from the
        metrics data collected. But it can be hard to configure and install
        it and hence Grafana is used instead.
        The chapter discusses how to install and
        configure and run Graphite and Grafana. The events are gathered
        from Reimann and sent in the form of metrics to Graphite. In order
        for the events to be consistent between Reimann and Graphite
        NTP is configured.
      </p>
  </details>
  <details>
    <summary class= "sum2">
        Chapter 5: Host-based monitoring with collectd
      </summary>
      <p> In this chapter, host-based data is collected and sent to Reimann.
        This is done by collectd which is a daemon acting as a monitoring
        collection agent. This will do the local monitoring and send
        it to Reimann. Collectd runs locally on the hosts and monitors
        and collects data from a variety of components. In order to
        collect data some plugins are enabled. Events collect the data
        and send them to graphite which in turn can be sent to grafana
        where they can be graphed.
      </p>
  </details>

  <details>
    <summary class= "sum2">
        Chapter 6: Using collectd events in Riemann
      </summary>
      <p>
        Following things about collectd event in Riemann are covered in this
        chapter.
        <li> The processes plugin is introduced to check for running processes.
          It generates a series of metrics for the processes such as ps_count
          metric which counts the number of running processes.</br>
          These three streams are utilized to measure availibility.</br>
            (i)The tagged stream wrapper</br>
            (ii)A stream that matches the threshold notification</br>
            (iii)A stream that matches expired events.</br>
        </li>
        <li>The other actions that can be taken using collectd notifications
          are redeploying the code,an attempt to restart a stopped service,
          trigger a configuration management run and many more.
        </li>
        <li>How to replicate some of the host monitoring checks is explained in
           detail.
        </li>
        <li>We can apply two mechanisms: data granularity and check functions,
           to make a better use of metric data.
        </li>
        <li>Constructing a new dashboard in graphana by creating a host
          dashboard, a host graph and memory graph is demonstarted here.
        </li>
        <li> Commercial tools such as New Relic, Circonus, DataDog etc and
          Open source tools such as Ganglia, Munin, StatsD etc are alternatives
           to collectd.
        </li>
      </p>
  </details>
  <details>
    <summary class= "sum2">
        Chapter 7: Containers - another kind of host
      </summary>
      <p> This chapter deals with monitoring in containers. Containers
        are light weighted and shortlived and this poses a problem
        in monitoring them. Docker does not have a default plugin for
        collectd and do an open source plugin is used. In docker, there
        is a daemon running on the host which creates and manages
        containers. We can interact with the daemon using the docker
        cli command or using an api that lets user query docker for stats.
        The docker collectd plugin is used to collect statistics on the
        containers. Once the statistics are collected they are
        converted to metrics and then sent to Reimann.
      </p>
  </details>
  <details>
      <summary class= "sum2">
        Chapter 8: Logs and Logging, covering structure logging and
        the ELK stack
      </summary>
      <p>In this chapter, weâ€™re introduced to the next layer of framework:
        logging. While the hosts, services, and applications generate crucial
        metrics and events, they also often generate logs that can tell
        useful things about their state and status. <br/>
        Additionally, logs are incredibly useful for diagnostic purposes
        when investigating an issue or incident. It is also described how
        these logs are captured, sent to a central store, and made use of
        to detect issues and provide diagnostic assistance. Metrics generation
        and graphs from these logs is also explained in brief. <br/>
        A log management platform is built to complement the other components
        of the monitoring framework. Some of the logs are collected and sent
        to Riemann and Graphite, to be recorded as metrics. They have also
        explained how to integrate Docker containers into logging. 
      </p>
  </details>

 <details>
      <summary class= "sum2">
        Chapter 9: Building monitored applications
      </summary>
  </details>


    <h4>Chapter 10: Alerting and Alert Management</h4>
    <h4>Chapters 11-13: Monitoring an application and stack</h4>
    </div>
    </div>
    </body>
</html>
